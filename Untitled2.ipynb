{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8EAhsInxmbmo+KOu2kaaj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/norakhaled112005-ctrl/A-Small-Project-of-Machine-Learning-Model/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr4xWWJKNO89"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "744d7c40"
      },
      "source": [
        "# Task\n",
        "Build a machine learning model to predict house prices, including data loading, preprocessing, model training, evaluation, and a summary of its performance with potential improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c296894"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "### Subtask:\n",
        "Load the dataset for house price prediction into a pandas DataFrame. We'll need to identify the features (independent variables) and the target variable (house prices).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fdd9054"
      },
      "source": [
        "**Reasoning**:\n",
        "To load the dataset, first, I need to import the pandas library, then read the 'house_prices.csv' file into a DataFrame, and finally display its first few rows and information to understand its structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "f77e958a",
        "outputId": "813efa0a-e759-4ee3-8bb0-5531a836aa06"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('house_prices.csv')\n",
        "\n",
        "print('First 5 rows of the DataFrame:')\n",
        "print(df.head())\n",
        "\n",
        "print('\\nDataFrame Info:')\n",
        "df.info()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'house_prices.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3500553055.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'house_prices.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'First 5 rows of the DataFrame:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'house_prices.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0f1bcc9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to load 'house_prices.csv' failed because the file was not found. I will correct the file path to use 'california_housing_train.csv' from the provided sample data directory, which is a suitable dataset for house price prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fbdd06e",
        "outputId": "130b34c4-e6f0-4cd3-fc41-10a930485529"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/california_housing_train.csv')\n",
        "\n",
        "print('First 5 rows of the DataFrame:')\n",
        "print(df.head())\n",
        "\n",
        "print('\\nDataFrame Info:')\n",
        "df.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
            "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
            "2    -114.56     33.69                17.0        720.0           174.0   \n",
            "3    -114.57     33.64                14.0       1501.0           337.0   \n",
            "4    -114.57     33.57                20.0       1454.0           326.0   \n",
            "\n",
            "   population  households  median_income  median_house_value  \n",
            "0      1015.0       472.0         1.4936             66900.0  \n",
            "1      1129.0       463.0         1.8200             80100.0  \n",
            "2       333.0       117.0         1.6509             85700.0  \n",
            "3       515.0       226.0         3.1917             73400.0  \n",
            "4       624.0       262.0         1.9250             65500.0  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17000 entries, 0 to 16999\n",
            "Data columns (total 9 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   longitude           17000 non-null  float64\n",
            " 1   latitude            17000 non-null  float64\n",
            " 2   housing_median_age  17000 non-null  float64\n",
            " 3   total_rooms         17000 non-null  float64\n",
            " 4   total_bedrooms      17000 non-null  float64\n",
            " 5   population          17000 non-null  float64\n",
            " 6   households          17000 non-null  float64\n",
            " 7   median_income       17000 non-null  float64\n",
            " 8   median_house_value  17000 non-null  float64\n",
            "dtypes: float64(9)\n",
            "memory usage: 1.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab121b21"
      },
      "source": [
        "**Reasoning**:\n",
        "The dataset has been successfully loaded and its structure inspected. Now, I need to explicitly identify the target variable ('median_house_value') and the features (all other columns) as required by the subtask, and then conclude the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ec431d0",
        "outputId": "9e45a6f0-5529-4d02-d311-f2a02d685d65"
      },
      "source": [
        "target_variable = 'median_house_value'\n",
        "features = [col for col in df.columns if col != target_variable]\n",
        "\n",
        "print(f\"Target Variable: {target_variable}\")\n",
        "print(f\"Features: {features}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Variable: median_house_value\n",
            "Features: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1a521ae"
      },
      "source": [
        "## Preprocess Data\n",
        "\n",
        "### Subtask:\n",
        "Clean and preprocess the loaded data. This may include handling missing values, encoding categorical features, and scaling numerical features to prepare it for model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f57bdcf"
      },
      "source": [
        "**Reasoning**:\n",
        "The first instruction is to check for missing values in the DataFrame `df`. I will use `df.isnull().sum()` to achieve this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1aa7e5d",
        "outputId": "487cf63a-f4ac-457b-9135-2b59968d9df4"
      },
      "source": [
        "print('Missing values in each column:')\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "longitude             0\n",
            "latitude              0\n",
            "housing_median_age    0\n",
            "total_rooms           0\n",
            "total_bedrooms        0\n",
            "population            0\n",
            "households            0\n",
            "median_income         0\n",
            "median_house_value    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c5ee0e3"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step showed no missing values. Now, I need to create the feature and target DataFrames, import and instantiate `StandardScaler`, apply it to the features, and then display the scaled features to verify the transformation, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2035bf36",
        "outputId": "346f92fa-8030-49b5-e5da-b6f0706bc73b"
      },
      "source": [
        "X = df[features]\n",
        "y = df[target_variable]\n",
        "\n",
        "print(\"Created X (features) and y (target variable) DataFrames.\")\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print('\\nFirst 5 rows of scaled features (X_scaled):')\n",
        "print(pd.DataFrame(X_scaled, columns=features).head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created X (features) and y (target variable) DataFrames.\n",
            "\n",
            "First 5 rows of scaled features (X_scaled):\n",
            "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0   2.619365 -0.671520           -1.079671     1.361695        1.764204   \n",
            "1   2.539569 -0.573264           -0.761872     2.296608        3.230441   \n",
            "2   2.494683 -0.905463           -0.920772    -0.882462       -0.866956   \n",
            "3   2.489696 -0.928857           -1.159121    -0.524186       -0.480230   \n",
            "4   2.489696 -0.961609           -0.682422    -0.545747       -0.506328   \n",
            "\n",
            "   population  households  median_income  \n",
            "0   -0.361184   -0.075998      -1.252543  \n",
            "1   -0.261865   -0.099404      -1.081483  \n",
            "2   -0.955354   -0.999252      -1.170105  \n",
            "3   -0.796793   -0.715774      -0.362600  \n",
            "4   -0.701830   -0.622148      -1.026454  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75bccd21"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "### Subtask:\n",
        "Select a suitable machine learning model (e.g., Linear Regression, Random Forest Regressor) and train it using the preprocessed data. We will split the data into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "690c58ba"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare for model training, I will first split the preprocessed data into training and testing sets using `train_test_split`. Then, I will import and instantiate a `LinearRegression` model, and finally train it on the training data, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "356a8d02",
        "outputId": "07c5fa79-17a7-4be2-f195-2eee451c18b7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Data split into training and testing sets successfully.\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# Instantiate and train the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nLinear Regression model instantiated and trained successfully.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split into training and testing sets successfully.\n",
            "X_train shape: (13600, 8)\n",
            "X_test shape: (3400, 8)\n",
            "y_train shape: (13600,)\n",
            "y_test shape: (3400,)\n",
            "\n",
            "Linear Regression model instantiated and trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89ccd1f8"
      },
      "source": [
        "## Evaluate Model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the trained model using appropriate metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), or R-squared to assess its prediction accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0c57143"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate the trained model, I will first make predictions on the test set, then import the required evaluation metrics from `sklearn.metrics`, calculate MAE, MSE, and R-squared, and finally print these metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6454118b",
        "outputId": "2ea2f0d9-e8d7-432c-ae95-5fe9e3799ccd"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Evaluation Metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"R-squared (R2) Score: {r2:.2f}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation Metrics:\n",
            "Mean Absolute Error (MAE): 49983.47\n",
            "Mean Squared Error (MSE): 4634658406.22\n",
            "R-squared (R2) Score: 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80f3727d"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a summary of the model's performance and discuss potential improvements or next steps for further development.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2e453a4"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "**1. What is the model's performance?**\n",
        "The Linear Regression model achieved a Mean Absolute Error (MAE) of 49983.47, a Mean Squared Error (MSE) of 4634658406.22, and an R-squared (R2) score of 0.66. This indicates that the model's predictions are, on average, off by approximately \\$49,983.47 from the actual median house values, and it explains 66% of the variance in house prices.\n",
        "\n",
        "**2. What are potential improvements or next steps for further development?**\n",
        "*   **Feature Engineering:** Explore creating new features from existing ones (e.g., bedrooms per room, population per household) to capture more complex relationships.\n",
        "*   **Model Selection & Hyperparameter Tuning:** Experiment with more advanced regression models (e.g., RandomForestRegressor, GradientBoostingRegressor, XGBoost) and tune their hyperparameters to potentially improve prediction accuracy.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The dataset `california_housing_train.csv` containing 17,000 entries and 9 columns was successfully loaded.\n",
        "*   The target variable was identified as `median_house_value`, and the remaining 8 columns were used as features.\n",
        "*   No missing values were found in any of the columns, simplifying the preprocessing step.\n",
        "*   Features were successfully scaled using `StandardScaler` to ensure all features contribute equally to the model.\n",
        "*   The data was split into training and testing sets with an 80/20 ratio, resulting in 13,600 samples for training and 3,400 samples for testing.\n",
        "*   A Linear Regression model was chosen and successfully trained on the scaled training data.\n",
        "*   The model achieved a Mean Absolute Error (MAE) of \\$49,983.47, a Mean Squared Error (MSE) of \\$4,634,658,406.22, and an R-squared (R2) score of 0.66 on the test set.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The current Linear Regression model provides a reasonable baseline for predicting house prices, explaining 66% of the variance.\n",
        "*   To improve model performance, consider exploring non-linear models or ensemble methods, as they might capture more complex relationships within the data that linear regression cannot.\n"
      ]
    }
  ]
}